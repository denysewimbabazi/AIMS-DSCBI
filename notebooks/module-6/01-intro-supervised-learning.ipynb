{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e971c31",
   "metadata": {},
   "source": [
    "# Introduction to Supervised Learning with scikit-learn\n",
    "\n",
    "Supervised learning is a core type of machine learning where models are trained on **labeled data** — that is, data containing both input features and known output labels. The model learns to map features to labels so that it can make accurate predictions on new, unseen data.  \n",
    "\n",
    "Common supervised learning tasks include **classification** (predicting discrete categories) and **regression** (predicting continuous values). The **scikit-learn** library provides a rich collection of tools and algorithms to implement these methods efficiently.\n",
    "\n",
    "In this tutorial, we will explore the **fundamentals of supervised learning** using **scikit-learn** in Python. You will learn how to:\n",
    "- Prepare and preprocess data for training\n",
    "- Build and train supervised learning models\n",
    "- Make predictions on unseen data\n",
    "- Evaluate model performance using key metrics\n",
    "\n",
    "We will cover essential concepts, algorithms, and practical examples to help you confidently get started with supervised learning in scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b194015",
   "metadata": {},
   "source": [
    "## Glossary of ML Terms\n",
    "There are a number of terms specific to Machine Learning that you will find repeatedly in this notebook. \n",
    "\n",
    "- **Learning**: In Machine Learning, you'll hear about \"learning a model.\" This is what you probably know as \n",
    "*fitting* or *estimating* a function, or *training* or *building* a model. These terms are all synonyms and are \n",
    "used interchangeably in the machine learning literature.\n",
    "- **Training Examples**: These are what you probably know as *data points* or *observations* or *rows* or *instances*. \n",
    "- **Features**: These are what you probably know as *independent variables*, *attributes*, *predictors*, \n",
    "or *explanatory variables.*\n",
    "- **Target Variable**: In some cases, we use this term to mean the variable being predicted\n",
    "- **Loss Function**: \n",
    "- **Underfitting**: This happens when a model is too simple and does not capture the structure of the data well \n",
    "enough.\n",
    "- **Overfitting**: This happens when a model is too complex or too sensitive to the noise in the data; this can\n",
    "result in poor generalization performance, or applicability of the model to new data. \n",
    "- **Regularization**: This is a general method to avoid overfitting by applying additional constraints to the model. \n",
    "For example, you can limit the number of features present in the final model, or the weight coefficients applied\n",
    "to the (standardized) features are small.\n",
    "- **Supervised learning** involves problems with one target or outcome variable (continuous or discrete) that we want\n",
    "to predict, or classify data into. Classification, prediction, and regression fall into this category. We call the\n",
    "set of explanatory variables $X$ **features**, and the outcome variable of interest $Y$ the **label**.\n",
    "- **Unsupervised learning** involves problems that do not have a specific outcome variable of interest, but rather\n",
    "we are looking to understand \"natural\" patterns or groupings in the data - looking to uncover some structure that \n",
    "we do not know about a priori. Clustering is the most common example of unsupervised learning, another example is \n",
    "principal components analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bc54d",
   "metadata": {},
   "source": [
    "## Scikit-learn Model Building Workflow\n",
    "\n",
    "Before training and testing machine learning models using **scikit-learn**, ensure your data meets the following criteria:\n",
    "\n",
    "-  **Data Format**  \n",
    "  Your input data must be structured as a **NumPy array**, **Pandas DataFrame**, or **SciPy sparse matrix**.\n",
    "\n",
    "- **Numeric Data Only**  \n",
    "  All features must be **numeric**. Convert categorical variables using encoding techniques such as:  \n",
    "  - `LabelEncoder`  \n",
    "  - `OneHotEncoder`  \n",
    "  - or `pd.get_dummies()`\n",
    "\n",
    "- **No Missing Values**  \n",
    "  scikit-learn models generally **cannot handle NaN values**. Address missing data by:  \n",
    "  - Dropping rows or columns: `df.dropna()`  \n",
    "  - Imputing missing values: `SimpleImputer`\n",
    "\n",
    "- **Consistent Feature Dimensions**\n",
    "  The number of columns (features) in your training data must match those used during prediction.\n",
    "\n",
    "\n",
    "### Model Building Process\n",
    "\n",
    "#### Overview\n",
    "The standard workflow for training and evaluating models in **scikit-learn** follows five key steps:\n",
    "\n",
    "1. **Data Preparation** → Clean, encode, and format data (numeric, no missing values).  \n",
    "2. **Initialize Model** → Create a model instance from `sklearn`.  \n",
    "3. **Fit Model** → Train the model using your training data (`X_train`, `y_train`).  \n",
    "4. **Predict** → Generate predictions on unseen data (`X_test`).  \n",
    "5. **Evaluate** → Assess model performance using appropriate metrics (e.g., accuracy, precision, RMSE).\n",
    "\n",
    "\n",
    "#### **Basic Syntax**\n",
    "```python\n",
    "from sklearn.module import Model\n",
    "\n",
    "# 1️⃣ Initialize the model\n",
    "model = Model()\n",
    "\n",
    "# 2️⃣ Train (fit) the model on data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 3️⃣ Predict on new or unseen data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 4️⃣ View or analyze results\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef38c9d",
   "metadata": {},
   "source": [
    "## Python Setup\n",
    "Before we begin, run the code cell below to initialize the libraries we'll be using in this assignment. We're already familiar with `numpy`, `pandas`, and `psycopg2` from previous tutorials. Here we'll also be using [`scikit-learn`](http://scikit-learn.org) to fit modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d337a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_classification, make_moons, load_wine, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                             mean_squared_error, r2_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6dbadb",
   "metadata": {},
   "source": [
    "## Working Directory Setup\n",
    "As usual, its a good practice to create global variables indicating where our data is sitting, where we will save models and other outputs as needes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db7c7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines and add your code to define the directories and files\n",
    "DIR_DATA = Path.cwd().parents[1].joinpath(\"data\")\n",
    "\n",
    "# Population and buildings Dataset\n",
    "FILE_BUILDINGS = DIR_DATA/\"adm4-population-buildings.csv\"\n",
    "\n",
    "# Diabetes Dataset\n",
    "FILE_DIABETES = DIR_DATA/\"diabetes.csv\"\n",
    "\n",
    "# NTL Dataset\n",
    "FILE_NTL = DIR_DATA/\"cell-ntl-2015-2020-2024.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268582b",
   "metadata": {},
   "source": [
    "## Introduction to Scikit-learn\n",
    "\n",
    "[Scikit-learn](https://scikit-learn.org/stable/) is one of the most widely used Python libraries for **machine learning**.  \n",
    "It provides efficient implementations of many **supervised** and **unsupervised** algorithms — such as regression, classification, clustering, and dimensionality reduction — all through a consistent and easy-to-use API.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Resources\n",
    "\n",
    "- [Base Documentation](https://scikit-learn.org/stable/documentation.html): The main entry point for all materials — includes tutorials, examples, API reference, and user guides.\n",
    "\n",
    "- [User Guide](https://scikit-learn.org/stable/user_guide.html): Conceptual explanations, code examples, and guidance on choosing the right algorithm.\n",
    "\n",
    "- [API Reference](https://scikit-learn.org/stable/api/index.html): The technical specification for all modules and classes — useful for checking available methods, parameters, and attributes for each model (e.g., `fit`, `predict`, `score`).\n",
    "\n",
    "\n",
    "### Understanding Models in Scikit-learn\n",
    "\n",
    "Each model (called an **estimator**) in scikit-learn encapsulates the main components of a *learner*:\n",
    "\n",
    "- **Hypothesis space:** defined by the model type and its hyperparameters (e.g., `LinearRegression`, `DecisionTreeClassifier`).  \n",
    "- **Risk (or loss):** defines how model performance is measured (e.g., `criterion='entropy'`, `loss='log_loss'`).  \n",
    "- **Optimization:** specifies how the best parameters are found (e.g., gradient descent, least squares, or tree splitting). These are also called solvers.\n",
    "\n",
    "You can inspect any estimator’s configuration and learn about its components using:\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.get_params()   # View hyperparameters defining the hypothesis space\n",
    "help(model)          # Access detailed documentation and references\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9b407",
   "metadata": {},
   "source": [
    "## Creating and Visualizing a Simple Two-Class Dataset\n",
    "\n",
    "In this step, we generate a **synthetic dataset** using `make_moons` from `sklearn.datasets`.  \n",
    "This dataset simulates two interleaving half-moon shapes, which is useful for visualizing and testing classification algorithms.\n",
    "\n",
    "We then:\n",
    "1. Convert the generated NumPy arrays into a **Pandas DataFrame** with descriptive column names (`Orbit_Position`, `Moon_Height`, and `Class`).\n",
    "2. Display key information about the dataset — its shape, features, and class distribution.\n",
    "3. Create a **scatter plot** to visualize how the two classes are distributed in feature space.\n",
    "   - Each color represents a class.\n",
    "   - The plot helps us understand the **non-linear decision boundary** that a classifier must learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the dataset with descriptive column names\n",
    "X_simple, y_simple = make_moons(n_samples=1200, noise=0.3, random_state=42)\n",
    "df_simple = pd.DataFrame(X_simple, columns=['Orbit_Position', 'Moon_Height'])\n",
    "df_simple['Class'] = y_simple\n",
    "\n",
    "print(f\"Dataset shape: {df_simple.shape}\")\n",
    "print(f\"Features: {list(df_simple.columns[:-1])}\")\n",
    "print(f\"Classes: {df_simple['Class'].unique()}\")\n",
    "print(f\"Samples per class: {df_simple['Class'].value_counts().values}\")\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df_simple['Orbit_Position'], df_simple['Moon_Height'], c=df_simple['Class'], \n",
    "                     cmap='RdYlBu', s=50, edgecolors='k', alpha=0.7)\n",
    "plt.xlabel('Feature 1 (Orbit_Position)')\n",
    "plt.ylabel('Feature 2 (Moon_Height)')\n",
    "plt.title('Two-Class Dataset: Moons')\n",
    "plt.colorbar(scatter, label='Class')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "print(\"\\nDataset visualization saved as 'dataset_visualization.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a88589",
   "metadata": {},
   "source": [
    "## Building Your First Classifier — K-Nearest Neighbors (KNN)\n",
    "The **K-Nearest Neighbors (KNN)** algorithm is one of the simplest yet powerful classification techniques.  \n",
    "It classifies a new data point based on the **majority class of its nearest neighbors** in the feature space. For technical details on KNN in sklearn cna be found [here](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification).\n",
    "\n",
    "### How KNN Works\n",
    "1. **Choose the number of neighbors (K)**  \n",
    "   This determines how many nearby points influence the prediction.  \n",
    "2. **Measure distance** between the new data point and all training points (commonly using Euclidean distance).  \n",
    "3. **Find the K closest training points**.  \n",
    "4. **Assign the most common class** among those neighbors to the new data point.\n",
    "\n",
    "### Key Hyperparameter\n",
    "- **K (`n_neighbors`)** — the number of neighbors to consider.\n",
    "  - Small `K` → More complex model (can **overfit** the training data).  \n",
    "  - Large `K` → Simpler model (can **underfit**, missing patterns).\n",
    "\n",
    "\n",
    "### Important Things to Know for Any ML Algorithm\n",
    "Regardless of the algorithm you use in **scikit-learn** (KNN, Decision Tree, Logistic Regression, etc.), these are the core concepts to understand:\n",
    "\n",
    "| Concept | Description |\n",
    "|----------|--------------|\n",
    "| **Model Objective** | What problem it solves — classification, regression, or clustering. |\n",
    "| **Assumptions** | The kind of data or relationships the algorithm expects (e.g., linear vs non-linear). |\n",
    "| **Key Hyperparameters** | The main knobs you can tune to control complexity and performance. |\n",
    "| **Training Process (`fit`)** | How the algorithm learns from data. |\n",
    "| **Prediction Process (`predict`)** | How it makes predictions on unseen data. |\n",
    "| **Evaluation Metrics** | How you measure performance (accuracy, precision, recall, RMSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be3c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93052eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature vector array\n",
    "X = df_simple[['Orbit_Position', 'Moon_Height']].values\n",
    "\n",
    "# Target variable vector array\n",
    "y = df_simple['Class'].values\n",
    "\n",
    "# Initialize and train the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust 'n_neighbors' as needed\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd873b30",
   "metadata": {},
   "source": [
    "### Making Predictions with a Trained Model\n",
    "\n",
    "After fitting (training) a model in **scikit-learn**, the next step is to use it to make predictions on new or unseen data.\n",
    "\n",
    "Most scikit-learn models provide multiple ways to generate predictions depending on what you need — **class labels**, **probabilities**, or **custom thresholds**.\n",
    "\n",
    "#### Predicting Class Labels\n",
    "\n",
    "Use the `.predict()` method to obtain the **final predicted class** for each observation:\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "#### Predicting Probabilities\n",
    "\n",
    "Use `.predict_proba()` to get **class membership probabilities** instead of hard labels.\n",
    "\n",
    "This method returns the probability of each sample belonging to each class.\n",
    "\n",
    "For binary classification, `y_prob[:, 1]` gives the probability of the **positive class**.\n",
    "\n",
    "Probabilities are particularly useful when you want to:\n",
    "- Adjust classification thresholds\n",
    "- Plot ROC or precision–recall curves\n",
    "- Evaluate metrics such as ROC-AUC\n",
    "```python\n",
    "y_prob = model.predict_proba(X_test)\n",
    "```\n",
    "\n",
    "#### Controlling the Classification Threshold\n",
    "\n",
    "By default, scikit-learn classifies a sample as class `1` if its predicted probability is greater than or equal to **0.5**.\n",
    "\n",
    "You can adjust this **decision threshold** to make the model more **sensitive** (focus on recall) or more **specific** (focus on precision).\n",
    "\n",
    "- Lower thresholds lead to more samples being classified as positive (↑ recall, ↓ precision)\n",
    "- Higher thresholds make the model more conservative (↓ recall, ↑ precision)\n",
    "```python\n",
    "threshold = 0.4\n",
    "y_pred_custom = (y_prob[:, 1] >= threshold).astype(int)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff49440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on new data points\n",
    "new_data = np.array([[0.5, 0.0], [1.5, 0.5], [0.0, 1.0]])\n",
    "\n",
    "# use .predict and .predict_proba methods to make predictions\n",
    "predicted_classes = knn.predict(new_data)\n",
    "predicted_probabilities = knn.predict_proba(new_data)\n",
    "print(f\"\\nPredictions for new data points {new_data} : {predicted_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ceb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b994694",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954645e",
   "metadata": {},
   "source": [
    "## Measuring Model Performance\n",
    "\n",
    "In classification, **accuracy** is one of the simplest and most commonly used metrics for evaluating a model’s performance.  \n",
    "It measures how often the classifier makes correct predictions.\n",
    "\n",
    "### Definition\n",
    "Accuracy is defined as the ratio of correctly predicted observations to the total number of observations:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- **TP** = True Positives  \n",
    "- **TN** = True Negatives  \n",
    "- **FP** = False Positives  \n",
    "- **FN** = False Negatives  \n",
    "\n",
    "### scikit-learn code\n",
    "```\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "```\n",
    "\n",
    "### Computing Accuracy \n",
    "<img src=\"/Users/dmatekenya/Library/CloudStorage/GoogleDrive-dmatekenya@gmail.com/My Drive/TEACHING/AIMS-DSCBI/docs/images/computing-perfomance.png\" alt=\"Computing Model Performance\" width=\"600\"/>\n",
    "\n",
    "Before training a model, we split the dataset into **training** and **test** sets to fairly evaluate performance.  \n",
    "- The **training set** is used by the model to learn patterns.  \n",
    "- The **test set** is kept aside to check how well the model generalizes to unseen data.\n",
    "\n",
    "We use `train_test_split` from **scikit-learn** to do this easily:\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_simple, y_simple, test_size=0.3, random_state=42, stratify=y_simple\n",
    ")\n",
    "\n",
    ")\n",
    "```\n",
    "- test_size=0.3 → 30% of data used for testing.\n",
    "- random_state=42 → ensures reproducibility.\n",
    "- stratify=y_simple → keeps class proportions the same in both sets.\n",
    "\n",
    "### Note on Reproducibility\n",
    "- Many operations in machine learning — like splitting data or initializing model parameters — involve **randomness**.  \n",
    "- By setting a fixed `random_state` (any integer), you **control the random number generator**, ensuring that every time you run the code, the random choices (such as which samples go into training or test sets) are **exactly the same**.\n",
    "- This makes your results **reproducible** — meaning you and others will get the same split, the same training data, and therefore the same model behavior across runs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16deb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_simple, y_simple, test_size=0.3, random_state=42, stratify=y_simple\n",
    ")\n",
    "\n",
    "# Initialize and train the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust 'n_neighbors' as needed\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted_classes = knn.predict(X_test)\n",
    "actual_classes = y_test\n",
    "accuracy = accuracy_score(actual_classes, predicted_classes)\n",
    "print(f\"\\nKNN Classifier Accuracy on Test Set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5909d",
   "metadata": {},
   "source": [
    "## Model Complexity\n",
    "\n",
    "Model complexity refers to how **flexible** or **expressive** a model is in learning patterns from data.  \n",
    "A model that is too simple may miss important patterns (**underfitting**), while one that is too flexible may learn noise as if it were signal (**overfitting**).\n",
    "\n",
    "In **K-Nearest Neighbors (KNN)**, model complexity is controlled by the number of neighbors (**K**):\n",
    "\n",
    "- **Larger K → Less complex model → May underfit**  \n",
    "  - The model becomes smoother and less sensitive to individual data points.  \n",
    "  - It may miss fine-grained patterns, resulting in poor performance on both training and test data.\n",
    "\n",
    "- **Smaller K → More complex model → May overfit**  \n",
    "  - The model closely follows training data points, including noise.  \n",
    "  - It performs very well on the training set but poorly on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Complexity in General Terms\n",
    "The concept of complexity applies to nearly all machine learning models:\n",
    "\n",
    "| Model Type | Complexity Controlled By | Effect of High Complexity |\n",
    "|-------------|--------------------------|----------------------------|\n",
    "| **KNN** | Number of neighbors (**K**) | Fits closely to local data; may overfit |\n",
    "| **Decision Tree** | Tree depth / number of leaves | Learns noise; deep trees overfit easily |\n",
    "| **Linear Regression / Logistic Regression** | Regularization strength (**C**, **alpha**) | Very small regularization may overfit |\n",
    "| **Neural Networks** | Number of layers and neurons | Highly flexible; prone to overfitting if not regularized |\n",
    "| **Random Forest / Boosting** | Number and depth of trees | Too many deep trees can overfit |\n",
    "\n",
    "---\n",
    "\n",
    "### The Goal\n",
    "The objective in model building is to find the **right balance** —  \n",
    "a model that is **complex enough** to capture real patterns but **simple enough** to generalize well to new data.\n",
    "\n",
    "This balance is often referred to as the **bias–variance tradeoff**:\n",
    "- **High bias (low complexity)** → underfitting  \n",
    "- **High variance (high complexity)** → overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e2595",
   "metadata": {},
   "source": [
    "### Visualizing Decision Boundaries and Misclassifications\n",
    "\n",
    "This section visualizes how the **K-Nearest Neighbors (KNN)** classifier makes predictions for different values of **K**.  \n",
    "\n",
    "1. **Decision Regions**  \n",
    "   - The background colors show the regions in feature space where the model predicts each class.  \n",
    "   - These are generated by creating a fine grid of points, passing them to the model’s `predict()` function, and coloring each region by its predicted class.\n",
    "\n",
    "2. **Training vs. Test Points**  \n",
    "   - **Training points** are plotted with partial transparency to show how the model fits the known data.  \n",
    "   - **Test points** are overlaid to evaluate generalization.\n",
    "\n",
    "3. **Misclassified Points**  \n",
    "   - Test samples that are **incorrectly classified** (model prediction ≠ true label) are outlined in red.  \n",
    "   - These help you see where the model struggles — typically around complex or overlapping decision boundaries.\n",
    "\n",
    "4. **Effect of K (Model Complexity)**  \n",
    "   - Small **K** → Complex boundaries that tightly follow training data (**may overfit**).  \n",
    "   - Large **K** → Smoother, simpler boundaries that may miss finer patterns (**may underfit**).\n",
    "\n",
    "By comparing plots across different values of **K**, you can visually understand the trade-off between **model complexity** and **generalization performance**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X_train, y_train, X_test, y_test, ax, title):\n",
    "    # Mesh over feature space\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_train[:, 0].min() - 0.5, X_train[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_train[:, 1].min() - 0.5, X_train[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Predict on grid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "    # Color maps (2-class example)\n",
    "    cm_bg = ListedColormap([\"#B3D4FF\", \"#FFD4A8\"])   # background (soft)\n",
    "    cm_pts = ListedColormap([\"#1f77b4\", \"#ff7f0e\"])  # points (bold)\n",
    "\n",
    "    # Regions + boundary line\n",
    "    ax.contourf(xx, yy, Z, alpha=0.35, cmap=cm_bg, antialiased=True)\n",
    "    ax.contour(xx, yy, Z, levels=np.unique(Z), colors=\"k\", linewidths=0.8, alpha=0.6)\n",
    "\n",
    "    # Train points (faded)\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_pts,\n",
    "               s=25, edgecolors=\"k\", alpha=0.45, label=\"Train\")\n",
    "\n",
    "    # Test predictions + misclassifications\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    correct = y_test_pred == y_test\n",
    "    wrong = ~correct\n",
    "\n",
    "    # Correct test points\n",
    "    ax.scatter(X_test[correct, 0], X_test[correct, 1], c=y_test[correct], cmap=cm_pts,\n",
    "               s=40, edgecolors=\"k\", alpha=0.95, marker=\"o\", label=\"Test (correct)\")\n",
    "\n",
    "    # Misclassified test points (red ring)\n",
    "    ax.scatter(X_test[wrong, 0], X_test[wrong, 1], facecolors=\"none\",\n",
    "               edgecolors=\"red\", s=120, linewidths=2.0, marker=\"o\", label=\"Test (misclassified)\")\n",
    "\n",
    "    ax.set_xlabel(\"Feature 1\")\n",
    "    ax.set_ylabel(\"Feature 2\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    ax.legend(loc=\"upper right\", fontsize=9, frameon=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_values = [1, 3, 5, 15, 50]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, k in enumerate(k_values):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = knn.score(X_train, y_train)\n",
    "    test_acc  = knn.score(X_test, y_test)\n",
    "\n",
    "    plot_decision_boundary(\n",
    "        knn, X_train, y_train, X_test, y_test, axes[idx],\n",
    "        f\"KNN (k={k})\\nTrain: {train_acc:.3f} | Test: {test_acc:.3f}\"\n",
    "    )\n",
    "    print(f\"K={k:2d} | Train: {train_acc:.3f} | Test: {test_acc:.3f}\")\n",
    "\n",
    "# remove empty subplot\n",
    "axes[-1].remove()\n",
    "plt.tight_layout()\n",
    "print(\"\\nDecision boundaries saved as 'knn_decision_boundaries.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81370364",
   "metadata": {},
   "source": [
    "## EXERCISE 1: Build and Compare 3 Classifiers\n",
    "\n",
    "### Objective\n",
    "Predict areas with high elderly population dependency using KNN, Random Forest, and Logistic Regression.\n",
    "\n",
    "### Dataset\n",
    "**File**: `adm4-population-buildings.csv` (Download from Datasets folder in Google Drive)\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Step 1: Create Target Variable\n",
    "- Calculate the 75th percentile of the `elderly_60` column\n",
    "- Create a binary target `high_dependence`:\n",
    "  - `1` if `elderly_60` ≥ 75th percentile\n",
    "  - `0` if `elderly_60` < 75th percentile\n",
    "- Check the class distribution\n",
    "\n",
    "#### Step 2: Prepare Features\n",
    "**Exclude these columns** from your features:\n",
    "- `'cell_id'`, `'province_name'`, `'district_name'`, `'sector_name'`, `'cell_name'`, `'elderly_60'`\n",
    "\n",
    "**Create**:\n",
    "- Feature matrix `X` (all columns except excluded ones and target)\n",
    "- Target vector `y` (the `high_dependence` column)\n",
    "\n",
    "#### Step 3: Train-Test Split\n",
    "- Split data: 70% train, 30% test (use `stratify=y` and `random_state=42`)\n",
    "\n",
    "#### Step 4: Build 3 Models\n",
    "Train and evaluate each model:\n",
    "\n",
    "**Model 1: KNN (n_neighbors=5)**\n",
    "- Report train and test accuracy\n",
    "\n",
    "**Model 2: Random Forest (n_estimators=100, max_depth=10)**\n",
    "- Report train and test accuracy\n",
    "- Show top 5 most important features\n",
    "\n",
    "**Model 3: Logistic Regression (max_iter=1000)**\n",
    "- Report train and test accuracy\n",
    "\n",
    "#### Step 5: Compare Results\n",
    "Create a comparison table with:\n",
    "- Model name\n",
    "- Training accuracy\n",
    "- Test accuracy\n",
    "- Overfitting gap (train - test)\n",
    "\n",
    "**Discussion questions**:\n",
    "1. Which model performs best on test data?\n",
    "2. Which model shows the most overfitting?\n",
    "3. Which model would you recommend for deployment? Why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40a9ea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>province_name</th>\n",
       "      <th>district_name</th>\n",
       "      <th>sector_name</th>\n",
       "      <th>cell_name</th>\n",
       "      <th>elderly_60</th>\n",
       "      <th>general_20</th>\n",
       "      <th>children_under5</th>\n",
       "      <th>youth_15_24</th>\n",
       "      <th>men_2020</th>\n",
       "      <th>women_2020</th>\n",
       "      <th>building_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWA.1.1.1.1_1</td>\n",
       "      <td>Amajyaruguru</td>\n",
       "      <td>Burera</td>\n",
       "      <td>Bungwe</td>\n",
       "      <td>Bungwe</td>\n",
       "      <td>241.693282</td>\n",
       "      <td>3855.623385</td>\n",
       "      <td>495.422606</td>\n",
       "      <td>758.093936</td>\n",
       "      <td>1850.711053</td>\n",
       "      <td>2004.912332</td>\n",
       "      <td>1435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWA.1.1.1.2_1</td>\n",
       "      <td>Amajyaruguru</td>\n",
       "      <td>Burera</td>\n",
       "      <td>Bungwe</td>\n",
       "      <td>Bushenya</td>\n",
       "      <td>229.611624</td>\n",
       "      <td>3669.128833</td>\n",
       "      <td>470.655098</td>\n",
       "      <td>720.896415</td>\n",
       "      <td>1761.457437</td>\n",
       "      <td>1907.671396</td>\n",
       "      <td>884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RWA.1.1.1.3_1</td>\n",
       "      <td>Amajyaruguru</td>\n",
       "      <td>Burera</td>\n",
       "      <td>Bungwe</td>\n",
       "      <td>Mudugari</td>\n",
       "      <td>109.718616</td>\n",
       "      <td>1756.630395</td>\n",
       "      <td>225.188715</td>\n",
       "      <td>345.073314</td>\n",
       "      <td>843.263769</td>\n",
       "      <td>913.366626</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RWA.1.1.1.4_1</td>\n",
       "      <td>Amajyaruguru</td>\n",
       "      <td>Burera</td>\n",
       "      <td>Bungwe</td>\n",
       "      <td>Tumba</td>\n",
       "      <td>318.065743</td>\n",
       "      <td>5174.177333</td>\n",
       "      <td>666.434701</td>\n",
       "      <td>1016.066328</td>\n",
       "      <td>2482.353880</td>\n",
       "      <td>2691.823510</td>\n",
       "      <td>1512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RWA.1.1.2.1_1</td>\n",
       "      <td>Amajyaruguru</td>\n",
       "      <td>Burera</td>\n",
       "      <td>Butaro</td>\n",
       "      <td>Gatsibo</td>\n",
       "      <td>335.976866</td>\n",
       "      <td>6046.478580</td>\n",
       "      <td>833.994018</td>\n",
       "      <td>1264.716616</td>\n",
       "      <td>2880.475354</td>\n",
       "      <td>3166.003226</td>\n",
       "      <td>2036.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id province_name district_name sector_name  cell_name  \\\n",
       "0  RWA.1.1.1.1_1  Amajyaruguru        Burera       Bungwe    Bungwe   \n",
       "1  RWA.1.1.1.2_1  Amajyaruguru        Burera       Bungwe  Bushenya   \n",
       "2  RWA.1.1.1.3_1  Amajyaruguru        Burera       Bungwe  Mudugari   \n",
       "3  RWA.1.1.1.4_1  Amajyaruguru        Burera       Bungwe     Tumba   \n",
       "4  RWA.1.1.2.1_1  Amajyaruguru        Burera       Butaro   Gatsibo   \n",
       "\n",
       "   elderly_60   general_20  children_under5  youth_15_24     men_2020  \\\n",
       "0  241.693282  3855.623385       495.422606   758.093936  1850.711053   \n",
       "1  229.611624  3669.128833       470.655098   720.896415  1761.457437   \n",
       "2  109.718616  1756.630395       225.188715   345.073314   843.263769   \n",
       "3  318.065743  5174.177333       666.434701  1016.066328  2482.353880   \n",
       "4  335.976866  6046.478580       833.994018  1264.716616  2880.475354   \n",
       "\n",
       "    women_2020  building_count  \n",
       "0  2004.912332          1435.0  \n",
       "1  1907.671396           884.0  \n",
       "2   913.366626           530.0  \n",
       "3  2691.823510          1512.0  \n",
       "4  3166.003226          2036.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(FILE_BUILDINGS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75b38b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high_dependence\n",
       "0    1626\n",
       "1     543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p75 = df['elderly_60'].quantile(0.75)\n",
    "\n",
    "df['high_dependence'] = (df['elderly_60'] >= p75).astype(int)\n",
    "\n",
    "df['high_dependence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b62a704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cell_id', 'province_name', 'district_name', 'sector_name ',\n",
       "       'cell_name', 'elderly_60', 'general_20', 'children_under5',\n",
       "       'youth_15_24', 'men_2020', 'women_2020', 'building_count',\n",
       "       'high_dependence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abe3cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['general_20', 'children_under5', 'youth_15_24', 'men_2020', 'women_2020', 'building_count', 'high_dependence']\n"
     ]
    }
   ],
   "source": [
    "exclude=['cell_id', 'province_name', 'district_name', 'sector_name ', 'cell_name', 'elderly_60']\n",
    "\n",
    "features = [col for col in df.columns if col not in exclude]\n",
    "print(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "553c81a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['general_20', 'children_under5', 'youth_15_24', 'men_2020', 'women_2020', 'building_count']].values\n",
    "y=df['high_dependence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c89eb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cc4f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6bbb0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Train Accuracy: 0.9393939393939394\n",
      "KNN Test Accuracy: 0.890937019969278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_train_acc = knn.score(X_train, y_train)\n",
    "knn_test_acc = knn.score(X_test, y_test)\n",
    "\n",
    "print(\"KNN Train Accuracy:\", knn_train_acc)\n",
    "print(\"KNN Test Accuracy:\", knn_test_acc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1608396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 0.9907773386034255\n",
      "Random Forest Test Accuracy: 0.9062980030721967\n",
      "\n",
      "Top 5 Important Features in Random Forest:\n",
      "women_2020         0.292448\n",
      "general_20         0.253612\n",
      "men_2020           0.169842\n",
      "youth_15_24        0.137256\n",
      "children_under5    0.097115\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_acc = rf.score(X_train, y_train)\n",
    "rf_test_acc = rf.score(X_test, y_test)\n",
    "\n",
    "print(\"Random Forest Train Accuracy:\", rf_train_acc)\n",
    "print(\"Random Forest Test Accuracy:\", rf_test_acc)\n",
    "\n",
    "# Feature importance\n",
    "feature_names = ['general_20', 'children_under5', 'youth_15_24', 'men_2020', 'women_2020', 'building_count']\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_names)\n",
    "top_features = importances.sort_values(ascending=False).head(5)\n",
    "print(\"\\nTop 5 Important Features in Random Forest:\")\n",
    "print(top_features)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e178e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 0.9314888010540184\n",
      "Logistic Regression Test Accuracy: 0.9185867895545314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_acc = lr.score(X_train, y_train)\n",
    "lr_test_acc = lr.score(X_test, y_test)\n",
    "\n",
    "print(\"Logistic Regression Train Accuracy:\", lr_train_acc)\n",
    "print(\"Logistic Regression Test Accuracy:\", lr_test_acc)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f6bd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "                 Model  Train Accuracy  Test Accuracy  Overfitting Gap\n",
      "0                  KNN        0.939394       0.890937         0.048457\n",
      "1        Random Forest        0.990777       0.906298         0.084479\n",
      "2  Logistic Regression        0.931489       0.918587         0.012902\n"
     ]
    }
   ],
   "source": [
    "# Comparison Table\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Random Forest', 'Logistic Regression'],\n",
    "    'Train Accuracy': [knn_train_acc, rf_train_acc, lr_train_acc],\n",
    "    'Test Accuracy': [knn_test_acc, rf_test_acc, lr_test_acc],\n",
    "})\n",
    "\n",
    "results['Overfitting Gap'] = results['Train Accuracy'] - results['Test Accuracy']\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4380d01",
   "metadata": {},
   "source": [
    "## Building Your First Regressor — Linear Regression\n",
    "\n",
    "The **Linear Regression** algorithm is one of the most fundamental and widely used techniques for regression problems.  \n",
    "It models the relationship between input features and a continuous target variable by fitting a **straight line (or hyperplane)** that minimizes prediction error.\n",
    "\n",
    "### How Linear Regression Works\n",
    "\n",
    "1. **Define the relationship**  \n",
    "   Linear Regression assumes a linear relationship between the input features $X$ and the target variable $y$.\n",
    "\n",
    "   - **Simple Linear Regression (one feature):**  \n",
    "     $$\n",
    "     \\hat{y} = \\beta_0 + \\beta_1 x\n",
    "     $$\n",
    "\n",
    "   - **Multiple Linear Regression (multiple features):**  \n",
    "     $$\n",
    "     \\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n\n",
    "     $$\n",
    "\n",
    "2. **Estimate coefficients**  \n",
    "   The algorithm finds the best-fit coefficients $\\beta_i$ that minimize the **error (or loss) function**, commonly defined as the **Sum of Squared Errors (SSE)**:\n",
    "   $$\n",
    "   SSE = \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n",
    "   $$\n",
    "\n",
    "   Minimizing this function ensures that the predicted values $\\hat{y}_i $ are as close as possible to the actual values $y_i$. This loss function is called Ordinary Least Squares (OLS).\n",
    "\n",
    "3. **Make predictions**  \n",
    "   Once trained, the model predicts new values by applying the learned coefficients to new input data.\n",
    "\n",
    "\n",
    "### Key Parameters and Concepts\n",
    "- **Coefficients (`coef_`)** → Represent how much each feature contributes to the target value.  \n",
    "- **Intercept (`intercept_`)** → The baseline prediction when all features are zero.  \n",
    "- **Assumption** → The relationship between inputs and target is approximately **linear**.\n",
    "\n",
    "\n",
    "### Example in scikit-learn\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train (fit) the model\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lin_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90054f",
   "metadata": {},
   "source": [
    "### Predicting blood glucose levels\n",
    "We will use the Diabetes dataset to predict blood glucose levels using Linear Regression. You can get details of the dataset [here](https://archive.ics.uci.edu/dataset/34/diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46382af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_csv(FILE_DIABETES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_diabetes[\"BMI\"], df_diabetes[\"Glucose\"])\n",
    "plt.ylabel(\"Blood Glucose (mg/dl)\")\n",
    "plt.xlabel(\"Body Mass Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c5f82",
   "metadata": {},
   "source": [
    "#### Fit a Simple Linear Regression\n",
    "- BMI predicts blood sugar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f64660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare the feature and target arrays\n",
    "X_bmi = df_diabetes[[\"BMI\"]].values\n",
    "y = df_diabetes[\"Glucose\"].values\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_bmi, y)\n",
    "predictions = reg.predict(X_bmi)\n",
    "\n",
    "plt.scatter(X_bmi, y)\n",
    "plt.plot(X_bmi, predictions, color='red')\n",
    "plt.ylabel(\"Blood Glucose (mg/dl)\")\n",
    "plt.xlabel(\"Body Mass Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1802e",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression\n",
    "- Features: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age\n",
    "- Target: BloodGlucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b874dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which features to use for multiple linear regression\n",
    "features = [\"Pregnancies\", \"BloodPressure\", \"SkinThickness\",\n",
    "            \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "\n",
    "# Prepare the feature and target arrays\n",
    "X = df_diabetes[features].values\n",
    "y = df_diabetes[\"Glucose\"].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Create a linear regression model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd697d5",
   "metadata": {},
   "source": [
    "### Evaluating Linear Regression Model\n",
    "\n",
    "After training a **Linear Regression** model, it’s important to evaluate how well it predicts continuous target values.  \n",
    "Unlike classification models that use metrics such as accuracy or precision, regression models are evaluated using **error-based** and **goodness-of-fit** metrics.\n",
    "\n",
    "\n",
    "\n",
    "#### 1. Mean Absolute Error (MAE)\n",
    "Measures the **average absolute difference** between the predicted and actual values.  \n",
    "It gives an idea of how far predictions are from the true values, on average.\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{m} \\sum_{i=1}^{m} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "- Easy to interpret in the same units as the target variable.  \n",
    "- Treats all errors equally, regardless of direction or magnitude.\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Mean Squared Error (MSE)\n",
    "Calculates the **average of squared differences** between predicted and actual values.  \n",
    "Squaring penalizes larger errors more heavily.\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "- Sensitive to outliers.  \n",
    "- Useful when larger errors are more undesirable.\n",
    "\n",
    "#### 3. Root Mean Squared Error (RMSE)\n",
    "The square root of MSE, providing an error measure in the **same units** as the target variable.\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{ \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 }\n",
    "$$\n",
    "\n",
    "- Easier to interpret than MSE.  \n",
    "- Penalizes large deviations more than MAE.\n",
    "\n",
    "\n",
    "#### 4. Coefficient of Determination (R² Score)\n",
    "Represents how much of the variance in the target variable is **explained** by the model.\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{ \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2 }{ \\sum_{i=1}^{m} (y_i - \\bar{y})^2 }\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ y_i$ → Actual values  \n",
    "- $\\hat{y}_i$ → Predicted values  \n",
    "- $\\bar{y}$ → Mean of actual values  \n",
    "\n",
    "- $R^2 = 1$ → Perfect fit  \n",
    "- $R^2 = 0$ → Model does no better than predicting the mean  \n",
    "- $R^2 < 0$ → Model performs worse than a simple mean predictor\n",
    "\n",
    "\n",
    "#### Example in scikit-learn\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Compute metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be396f",
   "metadata": {},
   "source": [
    "## Regularized Regression\n",
    "\n",
    "Recall that **Linear Regression** minimizes a loss function by choosing a coefficient (**a**) for each feature variable, along with an intercept (**b**).  \n",
    "However, large coefficients can lead to **overfitting** — the model fits the training data too closely and performs poorly on unseen data.\n",
    "\n",
    "**Regularization** addresses this problem by **penalizing large coefficients** in the loss function.\n",
    "\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "- **Loss function** = OLS loss function +  \n",
    "  $$\n",
    "  \\alpha \\times \\sum_{i=1}^{n} a_i^2\n",
    "  $$\n",
    "\n",
    "- Ridge penalizes large positive or negative coefficients.  \n",
    "- **α** is a parameter we need to choose.  \n",
    "- Selecting **α** is similar to choosing **k** in KNN.  \n",
    "- **Hyperparameter**: a variable used to optimize model parameters.\n",
    "\n",
    "#### α Controls Model Complexity\n",
    "- **α = 0** → Equivalent to OLS (may lead to overfitting).  \n",
    "- **Very high α** → Can lead to underfitting.\n",
    "\n",
    "\n",
    "### Lasso Regression\n",
    "\n",
    "- **Loss function** = OLS loss function +  \n",
    "  $$\n",
    "  \\alpha \\times \\sum_{i=1}^{n} |a_i|\n",
    "  $$\n",
    "\n",
    "- Lasso performs **feature selection** by shrinking some coefficients to zero.  \n",
    "- Coefficients of less important features become zero.  \n",
    "- Features with non-zero coefficients are considered **important** and retained in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da03db",
   "metadata": {},
   "source": [
    "### Try Out Ridge and LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "scores = []\n",
    "for alpha in [0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    score = ridge.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    print(f\"Alpha: {alpha}, R² Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04421483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "scores = []\n",
    "for alpha in [0.01, 1.0, 10.0, 20.0, 50.0]:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    lasso_pred = lasso.predict(X_test)\n",
    "    score = lasso.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    print(f\"Alpha: {alpha}, R² Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e99c5",
   "metadata": {},
   "source": [
    "### LASSO for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7013f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Prepare data for LASSO visualization\n",
    "X = df_diabetes.drop([\"Glucose\", \"Outcome\"], axis=1).values\n",
    "y = df_diabetes[\"Glucose\"].values\n",
    "names = df_diabetes.drop([\"Glucose\", \"Outcome\"], axis=1).columns\n",
    "\n",
    "# Fit LASSO model and get coefficients\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso_coef = lasso.fit(X, y).coef_\n",
    "\n",
    "# Visualize feature coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(names, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('LASSO Coefficients')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edecc93",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "When training machine learning models, we want to ensure that our model generalizes well to **unseen data**, not just the specific training set.  A simple train/test split might depend heavily on **how** the data was divided, which can make results unstable.  **Cross-Validation (CV)** helps overcome this limitation.\n",
    "\n",
    "### What is Cross-Validation?\n",
    "\n",
    "**Cross-Validation** is a resampling technique used to **evaluate model performance more reliably**.  \n",
    "It works by splitting the dataset into multiple **folds** (subsets), training the model on some folds, and testing it on the remaining ones.  \n",
    "This process is repeated several times so that each data point is used for both training and validation.\n",
    "\n",
    "\n",
    "### Example: 5-Fold Cross-Validation\n",
    "\n",
    "1. The data is split into **5 equal parts** (folds).  \n",
    "2. The model trains on **4 folds** and validates on the **remaining 1 fold**.  \n",
    "3. This process repeats **5 times**, each time using a different fold for validation.  \n",
    "4. The performance metrics from all runs are then **averaged** to obtain a more robust estimate.\n",
    "\n",
    "<img src=\"/Users/dmatekenya/My Drive (dmatekenya@gmail.com)/TEACHING/AIMS-DSCBI/docs/images/cross-validation.png\" alt=\"Computing Model Performance\" width=\"600\"/>\n",
    "\n",
    "Each fold gets a turn as the validation set, ensuring every sample is tested exactly once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027aaa9",
   "metadata": {},
   "source": [
    "### Cross-validation with sklearn \n",
    "scikit-learn provides **two approaches** for performing cross-validation:\n",
    "\n",
    "1. **Manual Cross-Validation (looping through folds)**  \n",
    "   - You explicitly create the folds using a splitter like `KFold` or `StratifiedKFold`.  \n",
    "   - Then, you manually loop over each fold to train and evaluate your model.  \n",
    "   - This gives you full control over what happens in each iteration.\n",
    "   ```python\n",
    "   from sklearn.model_selection import KFold\n",
    "   from sklearn.metrics import r2_score\n",
    "   from sklearn.linear_model import LinearRegression\n",
    "   import numpy as np\n",
    "\n",
    "   kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "   model = LinearRegression()\n",
    "   scores = []\n",
    "\n",
    "   for train_idx, val_idx in kf.split(X):\n",
    "       X_train, X_val = X[train_idx], X[val_idx]\n",
    "       y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "       model.fit(X_train, y_train)\n",
    "       y_pred = model.predict(X_val)\n",
    "       scores.append(r2_score(y_val, y_pred))\n",
    "\n",
    "   print(\"R² scores:\", scores)\n",
    "   print(\"Mean R²:\", np.mean(scores))\n",
    "\n",
    "2. **Automated Cross-Validation (using helper functions)**\n",
    "- The function cross_val_score() handles all the splitting, training, and evaluation automatically.\n",
    "- You simply provide the model, the data (X, y), the number of folds, and the scoring metric.\n",
    "``` python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Initialize model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform 5-fold cross-validation using R² as the metric\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(\"R² scores for each fold:\", scores)\n",
    "print(\"Mean R² score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store R² scores for each fold\n",
    "r2_scores = []\n",
    "\n",
    "print(\"Manual Cross-Validation Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Loop through each fold\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X), start=1):\n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # Initialize and train the model on this fold's training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "    \n",
    "    # Compute R² score for this fold\n",
    "    r2_fold = r2_score(y_val_fold, y_pred_fold)\n",
    "    r2_scores.append(r2_fold)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: R² = {r2_fold:.4f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mean R² Score: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(r2_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73393297",
   "metadata": {},
   "source": [
    "## EXERCISE 2: Comparing Regressors with Cross-Validation\n",
    "\n",
    "### Datasets\n",
    "You will use the following datasets for this exercise:\n",
    "1. **adm4-population-buildings.csv** — [Download here](https://drive.google.com/file/d/1QAcOGf33GjLNtU1Xkku2WJayMa07gfLJ/view?usp=sharing)  \n",
    "2. **cell-ntl-2015-2020-2024.csv** — [Download here](https://drive.google.com/file/d/1f_4fiqxIejly0YmC088s9bxOfrABv9Sz/view?usp=share_link)\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### 1. Data Preparation\n",
    "- Extract only the **2024 night light** data from `cell-ntl-2015-2020-2024.csv`.  \n",
    "- Merge it with `adm4-population-buildings.csv` using the **common key column**.  \n",
    "- Drop all redundant or non-numeric columns that are not useful for regression.  \n",
    "- Ensure there are no missing values in your final dataset.\n",
    "\n",
    "#### 2. Define the Prediction Task\n",
    "- Your **target variable** is `general_population`.  \n",
    "- Use all remaining numeric columns as **predictor variables**.\n",
    "\n",
    "#### 3. Model Comparison\n",
    "Build and evaluate the following regression models:\n",
    "- **Linear Regression**  \n",
    "- **Ridge Regression**  \n",
    "- **Lasso Regression**\n",
    "\n",
    "Use **5-fold cross-validation** to evaluate model performance for each regressor.  \n",
    "Compute and compare 2 metrics:\n",
    "- **Mean Squared Error (MSE)**\n",
    "- **R² Score**\n",
    "\n",
    "You can use `cross_val_score` or `cross_validate` from `sklearn.model_selection` to automate the process.\n",
    "\n",
    "#### 4. Report Results\n",
    "- Summarize the **average performance across folds** for each model.  \n",
    "- Identify which model performs **best** based on your chosen evaluation metric(s).  \n",
    "- Discuss whether regularization (Ridge or Lasso) improves model generalization.\n",
    "\n",
    "#### 5. Feature Selection with Lasso\n",
    "- Using the best-performing **Lasso model**, identify the **3 most important features**.  \n",
    "- Report which features were **retained (non-zero coefficients)** and interpret their possible relevance to predicting population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147df0af",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "**Ridge/Lasso Regression:** Choosing alpha  \n",
    "**KNN:** Choosing n_neighbors  \n",
    "**Hyperparameters:** Parameters we specify before fitting the model, like alpha and n_neighbors\n",
    "\n",
    "### Choosing the Correct Hyperparameters\n",
    "\n",
    "1. Try lots of different hyperparameter values\n",
    "2. Fit all of them separately\n",
    "3. See how well they perform\n",
    "4. Choose the best performing values\n",
    "\n",
    "This process is called **hyperparameter tuning**.\n",
    "\n",
    "It is essential to use **cross-validation** to avoid overfitting to the test set.  \n",
    "We can still split the data and perform cross-validation on the training set.  \n",
    "We withhold the test set for final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fbea3",
   "metadata": {},
   "source": [
    "### GridSearchCV in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {\"alpha\": np.arange(0.0001, 1, 0.1),\n",
    "              \"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge, param_grid, cv=kf)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "print(ridge_cv.best_params_, ridge_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427b702",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa9fe760",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
